{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['discourse_text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./input/train.csv\")\n",
    "tokenizer = Tokenizer()\n",
    "texts = [x.lower() for x in train_df['discourse_text'].values]\n",
    "tokenizer.fit_on_texts(texts)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "# print(tokenizer.word_index)\n",
    "# print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36765/36765 [01:55<00:00, 319.38it/s]\n"
     ]
    }
   ],
   "source": [
    "input_sequences = []\n",
    "\n",
    "for text in tqdm(texts):\n",
    "    # print(text)\n",
    "    token_list = tokenizer.texts_to_sequences(text)\n",
    "    # print(token_list)\n",
    "    for i in range(1,len(token_list)):\n",
    "        ngram_sequences = token_list[:i+1]\n",
    "        input_sequences.append(ngram_sequences)\n",
    "\n",
    "max_sequences_len = max([len(x) for x in input_sequences])\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_tensor = []\n",
    "for x in texts[:10]:\n",
    "    texts_tensor.append(nlp(x).vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_tensor = tf.reshape(texts_tensor,[10,1,300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10, 300), dtype=float32, numpy=\n",
       "array([[[-1.7310259 ,  1.2019125 , -3.6277354 , ...,  0.0363916 ,\n",
       "         -2.994872  ,  1.4502984 ],\n",
       "        [-0.8571301 ,  1.7046484 , -3.1711113 , ..., -0.6690958 ,\n",
       "         -4.5095615 ,  1.7122338 ],\n",
       "        [-0.7345443 ,  3.1622272 , -2.7153568 , ...,  0.02443947,\n",
       "         -3.869576  ,  2.00546   ],\n",
       "        ...,\n",
       "        [-3.285236  ,  0.88648003, -2.619274  , ..., -0.62785   ,\n",
       "         -2.2943168 ,  4.129184  ],\n",
       "        [-1.8806963 ,  2.1315725 , -3.1053443 , ..., -0.08605026,\n",
       "         -2.4896052 ,  2.1499102 ],\n",
       "        [-2.3043728 ,  0.34056365, -2.421952  , ..., -1.7717329 ,\n",
       "         -2.6810198 ,  0.9267128 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in texts_tensor:\n",
    "    print(x.shape)\n",
    "    for y in x:\n",
    "        print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# model.add(keras.layers.Embedding(total_words, 100, input_length=max_sequences_len-1))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(300,return_sequences=True)))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150)))\n",
    "model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "adam = tf.keras.optimizers.Adam(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = keras.layers.Bidirectional(keras.layers.LSTM(150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_df['discourse_effectiveness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(Keys,values,features):\n",
    "    init = tf.lookup.KeyValueTensorInitializer(Keys,values)\n",
    "    table = tf.lookup.StaticHashTable(init,default_value=-1)\n",
    "    return table.lookup(tf.constant(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = tf.constant(['Adequate', 'Effective','Ineffective'])\n",
    "\n",
    "TARGET_LABELS = tf.constant([0,1,2])\n",
    "y_train = tf.one_hot(get_label( TARGET, TARGET_LABELS, labels[:10]),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 3])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.reshape(y_train,[10,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ys = tf.keras.utils.to_categorical(labels[:10], num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 200, 300])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 1.1155 - accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5110 - accuracy: 0.8000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6300 - accuracy: 0.8000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0131 - accuracy: 0.8000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8762 - accuracy: 0.8000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6743 - accuracy: 0.8000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5661 - accuracy: 0.8000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5381 - accuracy: 0.8000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5233 - accuracy: 0.8000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4924 - accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16b3b492a10>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layers(tf.reshape(text_1,[1,1,300]))\n",
    "model.fit(texts_tensor,y_train,epochs=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([200, 3])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_batches = tf.data.Dataset.from_tensor_slices(texts_tensor).batch(32)\n",
    "y_batches = tf.data.Dataset.from_tensor_slices(y_train).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = tf.data.Dataset.zip( (text_batches , y_batches) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_batch, y_batch in data_set.batch(10):\n",
    "    for x in x_batch:\n",
    "        for y in x:\n",
    "            print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.random.normal([32, 10, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ZipDataset element_spec=(TensorSpec(shape=(None, 2, 300), dtype=tf.float32, name=None), TensorSpec(shape=(None, 3), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 8), dtype=float32, numpy=\n",
       "array([[-1.8753177 ,  0.39924157, -1.3061185 , -0.09128398, -1.8712283 ,\n",
       "        -0.34483775, -0.57712895,  1.4799764 ],\n",
       "       [ 0.11513742, -1.3900502 ,  0.20380816,  0.6482683 , -1.6172249 ,\n",
       "         0.3066741 ,  0.07384012, -0.9795225 ],\n",
       "       [ 0.87422425,  0.78189695,  0.01507624,  0.17949   , -1.6737931 ,\n",
       "        -0.45730028, -0.81652325,  0.3563014 ],\n",
       "       [-0.19982137,  0.84976166, -0.59731007, -0.96287096, -0.6522744 ,\n",
       "        -0.16280177, -1.1096549 ,  1.2835126 ],\n",
       "       [ 1.3445842 , -0.97756916, -0.31488225,  0.58931786, -0.13619326,\n",
       "         1.5717092 ,  0.32090935,  0.80906075],\n",
       "       [ 1.4670334 , -0.119016  , -0.06259945,  1.2847294 , -1.0686811 ,\n",
       "        -0.51476103, -0.40006658,  0.66146886],\n",
       "       [ 1.060258  ,  0.70658004,  0.45708534, -1.5078332 , -1.2828417 ,\n",
       "        -0.70203847,  0.09950235, -1.3442135 ],\n",
       "       [ 1.0623285 ,  0.75111175, -1.0949779 ,  0.32393587, -1.5980583 ,\n",
       "        -1.4131682 ,  0.32177702,  0.06165824],\n",
       "       [-1.1097913 , -0.5550918 , -0.19037557, -1.2704947 , -1.957086  ,\n",
       "        -1.2541072 ,  1.2266876 , -0.60341763],\n",
       "       [-0.29385883, -0.4129542 , -0.4209914 , -0.09793455,  1.1722451 ,\n",
       "         0.15445971, -1.058159  ,  1.9375452 ]], dtype=float32)>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ccc9907020a360c0774b7240d7189d7caac06a5804f44f1a6c385a36278d3a41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
