{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q -U \"tensorflow-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "import tensorflow_hub as hub\n",
    "from tqdm import tqdm\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./input/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data using Spacy \n",
    "\n",
    "To use \"en_core_web_lg\" nlp package please run this command in your terminal , else error will throw\n",
    "* python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "doc = nlp(train_df['discourse_text'][0]) # first text from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Hi, i'm Isaac, i'm going to be writing about how this face on \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " is a natural landform or if there is life on \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " that made it. The story is about how \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NASA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " took a picture of \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " and a face was seen on the planet. \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NASA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " doesn't know if the landform was created by life on \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", or if it is just a natural landform. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "displacy is to render the text in the notebook by specific terms\n",
    "ent = will display all the entities are there in a text\n",
    "dep = will display graph based ytantic dependeices and will display parts of speech \n",
    "\"\"\"\n",
    "displacy.render(doc, style=\"ent\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Hi, 'INTJ', 'hi'],\n",
       " [,, 'PUNCT', ','],\n",
       " [i, 'PRON', 'I'],\n",
       " ['m, 'AUX', 'be'],\n",
       " [Isaac, 'PROPN', 'Isaac'],\n",
       " [,, 'PUNCT', ','],\n",
       " [i, 'PRON', 'I'],\n",
       " ['m, 'AUX', 'be'],\n",
       " [going, 'VERB', 'go'],\n",
       " [to, 'PART', 'to']]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parts of speech of the text - text.pos_\n",
    "# Lemma will return the base of the word - text.lemma_\n",
    "pos_list = []\n",
    "for text in doc[0:10]:\n",
    "    pos_list.append([text , text.pos_ , text.lemma_])\n",
    "pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.enable_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Hi, i'm Isaac, i'm going to be writing about how this face on \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " is a natural landform or if there is life on \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " that made it. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The story is about how \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NASA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " took a picture of \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " and a face was seen on the planet. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NASA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " doesn't know if the landform was created by life on \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", or if it is just a natural landform. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# doc1 = nlp(doc)\n",
    "for text in doc.sents:\n",
    "#    for _ in text:\n",
    "    displacy.render(text,style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_num = nlp(train_df['discourse_text'][0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hi, i'm isaac, i'm going to be writing about how this face on mars is a natural landform or if there is life on mars that made it. the story is about how nasa took a picture of mars and a face was seen on the planet. nasa doesn't know if the landform was created by life on mars, or if it is just a natural landform. \""
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Hi, i'm Isaac, i'm going to be writing about how this face on \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " is a natural landform or if there is life on \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " that made it. The story is about how \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NASA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " took a picture of \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " and a face was seen on the planet. \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NASA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " doesn't know if the landform was created by life on \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", or if it is just a natural landform. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc,style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "_VOCAB = [b\"[UNK]\", b\"[MASK]\", b\"[RANDOM]\", b\"[CLS]\", b\"[SEP]\",b\"[END]\"]\n",
    "\n",
    "_START_TOKEN = _VOCAB.index(b'[CLS]')\n",
    "_END_TOKEN = _VOCAB.index(b'[END]')\n",
    "_MASK_TOKEN = _VOCAB.index(b'[MASK]')\n",
    "_RANDOM_TOKEN = _VOCAB.index(b'[RANDOM]')\n",
    "_SEP_TOKEN = _VOCAB.index(b'[SEP]')\n",
    "_UNKNOWN_TOKEN = _VOCAB.index(b'[UNK]')\n",
    "\n",
    "_VOCAB_SIZE = len(_VOCAB)\n",
    "\n",
    "lookuptable = tf.lookup.StaticVocabularyTable(\n",
    "                tf.lookup.KeyValueTensorInitializer(\n",
    "                    keys = _VOCAB,\n",
    "                    key_dtype=tf.string,\n",
    "                    values=tf.range(_VOCAB_SIZE,dtype=tf.int64),\n",
    "                    value_dtype=tf.int64\n",
    "                ),\n",
    "                num_oov_buckets=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. \""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['discourse_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[[b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]'],\n",
       "  [b'[UNK]']]]>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokenzier = text.BertTokenizer(lookuptable,token_out_type=tf.string)\n",
    "text_tokenzier.tokenize(\"Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "preprocessor = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = preprocessor([train_df['discourse_text'][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_word_ids': <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
       " array([[  101,  7632,  1010,  1045,  1005,  1049,  7527,  1010,  1045,\n",
       "          1005,  1049,  2183,  2000,  2022,  3015,  2055,  2129,  2023,\n",
       "          2227,  2006,  7733,  2003,  1037,  3019,  2455, 14192,  2030,\n",
       "          2065,  2045,  2003,  2166,  2006,  7733,  2008,  2081,  2009,\n",
       "          1012,  1996,  2466,  2003,  2055,  2129,  9274,  2165,  1037,\n",
       "          3861,  1997,  7733,  1998,  1037,  2227,  2001,  2464,  2006,\n",
       "          1996,  4774,  1012,  9274,  2987,  1005,  1056,  2113,  2065,\n",
       "          1996,  2455, 14192,  2001,  2580,  2011,  2166,  2006,  7733,\n",
       "          1010,  2030,  2065,  2009,  2003,  2074,  1037,  3019,  2455,\n",
       "         14192,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]])>,\n",
       " 'input_type_ids': <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
       " array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>,\n",
       " 'input_mask': <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
       " array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\",trainable=True)\n",
    "outputs = encoder(encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_output = outputs['pooled_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Output tensors of a Functional model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: [-1.6388502e+00  9.8170102e-01 -3.5083053e+00 -1.4603213e+00\n  2.5865364e+00 -6.5126456e-02  3.0316040e-01  4.1716142e+00\n  1.3215761e-01  7.6925611e-01  6.2784634e+00  1.9529140e+00\n -2.8802567e+00  1.0653728e+00  2.5061550e+00  9.2077428e-01\n  1.9302834e+00 -1.1735537e+00 -5.7096797e-01 -2.2701375e+00\n  2.4995437e+00 -9.7327185e-01 -1.5777076e+00 -1.0989767e+00\n -9.2450380e-01 -2.3687189e+00 -1.3157930e+00 -2.1876419e+00\n -1.2413212e+00  1.6353768e+00 -7.3108107e-01 -1.3623276e+00\n -1.8963171e+00 -1.0639617e+00 -1.5508072e+00 -4.5057386e-01\n -5.6444073e-01  1.4443216e+00  3.4425600e+00  1.4573760e+00\n -6.5039366e-01  3.1811258e-01  9.4922084e-01 -7.9766989e-01\n -9.8454535e-01  2.4077947e+00  2.1995032e+00 -4.0448079e+00\n -9.2925215e-01  2.2726848e+00 -1.7401269e-01  5.2170229e-01\n  4.3472964e-01 -4.4175196e+00 -1.7052845e+00 -1.8668878e-01\n  1.6842152e+00  1.8334684e+00  1.9559307e-02  1.0533800e+00\n  1.6240237e+00 -5.1595324e-01 -1.0556552e+00 -1.8572745e+00\n -4.4830614e-01  1.2938776e+00 -2.6437109e+00 -3.9279304e+00\n  6.7561090e-01  3.3770020e+00 -1.2377387e+00  6.3179296e-01\n -3.0890808e+00 -9.2200398e-01 -7.5395477e-01  1.4635874e+00\n -2.6328647e+00  5.8671838e-01 -3.1122048e+00 -1.4853683e+00\n -3.5925019e+00 -9.0457928e-01  2.6442163e+00  7.3590726e-01\n  1.6794238e+00 -3.2729104e-01 -1.7280924e-01 -2.1610258e+00\n  2.0986254e+00 -1.4968735e+00 -1.1144214e+00 -2.0745757e+00\n  2.4610586e+00 -5.3111992e+00  6.6212231e-01 -2.6543918e+00\n  1.2785629e+00 -1.1522425e+00 -1.0213540e-01 -9.0020829e-01\n  2.2124939e+00  1.2656025e+00  1.7484128e+00  2.4436119e+00\n -5.1200920e-01  3.9480648e+00  3.5562128e-01 -1.0096823e+00\n -1.2655197e+00 -1.3710920e+00  4.8538360e-01  1.0193845e+00\n -6.8567353e-01  1.5078901e+00  1.1484847e+00  1.1693500e+00\n -1.9256405e+00 -8.6966836e-01  2.0926356e-01 -1.5142665e+00\n -1.6797714e+00 -2.8695924e+00 -4.1191903e-01  1.9779531e+00\n -1.5834309e+00 -3.6900871e+00  1.5921605e+00 -1.4703733e+00\n  2.0056138e+00 -1.2378743e+00 -2.1566374e+00  3.4771997e-01\n  2.8722532e+00 -3.0759056e+00 -3.9849904e-01  8.1287807e-01\n -1.0720620e+00 -1.5841624e+00  4.3312273e+00 -2.4475791e+00\n -1.7784846e+00 -1.2929100e+00  8.7318581e-01  1.7913809e+00\n  7.3232859e-01  6.6992486e-01 -3.7304037e+00  2.6036674e-01\n  7.4065693e-02  9.6584308e-01 -1.1477481e+00  3.0739110e+00\n -5.9495438e-02 -8.1894077e-02 -7.4207342e-01  1.5691304e+00\n  3.0630310e+00  7.4038243e-01 -9.9650455e-01 -5.5160624e-01\n -1.3176674e+00 -3.2868459e+00 -8.1009310e-01  3.2517961e-01\n -2.6843810e+00 -9.0371686e-01 -3.4887893e+00  3.0896013e+00\n -9.3788320e-01  1.1897588e-01  9.6492255e-01 -8.9322871e-01\n  1.9874659e+00  1.5735323e+00  1.2174255e+00 -1.6569481e+00\n -9.5430487e-01 -2.6639646e-01 -2.9983237e+00 -2.1904733e+00\n -3.8639185e-01  6.2347645e-01  3.7714205e+00 -1.0601476e+00\n -1.0001069e+00  8.8191777e-01 -1.4612850e+00 -1.5596120e+00\n  1.3283343e+00  2.1000891e+00 -1.1779108e+00 -7.5683695e-01\n -1.7087047e+00 -7.1810716e-01 -6.1134970e-01 -2.4914935e-01\n -2.0177565e+00  7.2806549e-01  5.8099061e-01  1.4585537e+00\n -2.2939477e+00 -1.5291135e+00 -1.5099289e+00 -3.2321315e+00\n  6.1497670e-01  2.3320947e+00 -3.6664815e+00  6.2144011e-01\n -1.7255962e+00 -1.7187570e+00  2.2244904e+00  3.1124595e-01\n -1.9233246e+00  2.9262867e+00 -6.4434284e-01  6.5985173e-01\n  3.7461834e-03 -2.1112857e+00 -2.0878343e-01  1.0766115e+00\n -2.4515038e+00 -1.2157291e+00  6.6348791e-01  6.9953376e-01\n -5.6131536e-01 -1.6413348e+00  1.0857105e+00  1.4758211e+00\n  2.8117948e+00 -5.8064111e-02  1.6607553e-01 -4.7130775e+00\n -3.7049344e-01  1.3344603e+00  3.2366285e-01  1.0987030e+00\n -1.6346524e+00  1.1686294e+00  2.3944382e-01 -7.4882221e-01\n -1.4736948e+00 -3.0995882e-01  2.0879261e+00  3.3721754e-01\n -1.7368939e+00 -6.8033016e-01 -2.5193825e+00  1.2684470e+00\n  1.2490822e+00  2.9506516e+00 -1.3877697e-01 -6.4308608e-01\n -5.3445492e+00 -6.6599011e-01  1.7340769e-01 -3.0730164e+00\n  1.4694253e+00  1.5803531e+00 -7.4518591e-02  1.3910463e+00\n  2.6198113e-01  5.9126120e+00  4.1149664e+00  3.7905061e+00\n  6.1283034e-01 -1.8621488e-01  4.1750160e-01  2.4414737e+00\n -4.9565382e+00  1.5875116e-01  1.8287042e+00 -1.5839664e+00\n -5.1569861e-01 -2.1890948e+00  6.2454796e-01  1.0140430e-01\n  2.9440637e+00 -3.1108832e-01 -1.0851415e+00  1.9169365e+00\n  1.4631879e-01 -5.2558589e-01  1.0758524e+00  1.8683195e+00\n  4.1380458e+00 -6.2021714e-01  9.9774951e-01  1.1183604e+00\n -1.9896706e+00  1.4364551e+00  1.7458793e+00 -9.9778289e-01\n  1.3292212e+00  2.3253212e-02 -1.7088943e+00  5.1940012e-01\n  1.2845680e+00 -2.0319632e-01 -3.2012630e+00  1.5914700e+00]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Automation\\python\\nlp_feedback_predict\\Preprocessing.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Automation/python/nlp_feedback_predict/Preprocessing.ipynb#ch0000011?line=0'>1</a>\u001b[0m embedding_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mModel(text_input, doc\u001b[39m.\u001b[39;49mvector)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Automation/python/nlp_feedback_predict/Preprocessing.ipynb#ch0000011?line=1'>2</a>\u001b[0m sentences \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant([\u001b[39m\"\u001b[39m\u001b[39mBasha\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Automation/python/nlp_feedback_predict/Preprocessing.ipynb#ch0000011?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(embedding_model(sentences))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    586\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 587\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    588\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    589\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\functional.py:148\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[1;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m([functional_utils\u001b[39m.\u001b[39mis_input_keras_tensor(t)\n\u001b[0;32m    146\u001b[0m               \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(inputs)]):\n\u001b[0;32m    147\u001b[0m     inputs, outputs \u001b[39m=\u001b[39m functional_utils\u001b[39m.\u001b[39mclone_graph_nodes(inputs, outputs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_graph_network(inputs, outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    586\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 587\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    588\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    589\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\functional.py:186\u001b[0m, in \u001b[0;36mFunctional._init_graph_network\u001b[1;34m(self, inputs, outputs)\u001b[0m\n\u001b[0;32m    183\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(tensor, \u001b[39m'\u001b[39m\u001b[39m_keras_history\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs):\n\u001b[0;32m    184\u001b[0m     base_layer_utils\u001b[39m.\u001b[39mcreate_keras_history(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nested_outputs)\n\u001b[1;32m--> 186\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_graph_inputs_and_outputs()\n\u001b[0;32m    188\u001b[0m \u001b[39m# A Network does not create weights of its own, thus it is already\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[39m# built.\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\functional.py:740\u001b[0m, in \u001b[0;36mFunctional._validate_graph_inputs_and_outputs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m'\u001b[39m\u001b[39m_keras_history\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    739\u001b[0m   cls_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m--> 740\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mOutput tensors of a \u001b[39m\u001b[39m{\u001b[39;00mcls_name\u001b[39m}\u001b[39;00m\u001b[39m model must be \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    741\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mthe output of a TensorFlow `Layer` \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    742\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m(thus holding past layer metadata). Found: \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Output tensors of a Functional model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: [-1.6388502e+00  9.8170102e-01 -3.5083053e+00 -1.4603213e+00\n  2.5865364e+00 -6.5126456e-02  3.0316040e-01  4.1716142e+00\n  1.3215761e-01  7.6925611e-01  6.2784634e+00  1.9529140e+00\n -2.8802567e+00  1.0653728e+00  2.5061550e+00  9.2077428e-01\n  1.9302834e+00 -1.1735537e+00 -5.7096797e-01 -2.2701375e+00\n  2.4995437e+00 -9.7327185e-01 -1.5777076e+00 -1.0989767e+00\n -9.2450380e-01 -2.3687189e+00 -1.3157930e+00 -2.1876419e+00\n -1.2413212e+00  1.6353768e+00 -7.3108107e-01 -1.3623276e+00\n -1.8963171e+00 -1.0639617e+00 -1.5508072e+00 -4.5057386e-01\n -5.6444073e-01  1.4443216e+00  3.4425600e+00  1.4573760e+00\n -6.5039366e-01  3.1811258e-01  9.4922084e-01 -7.9766989e-01\n -9.8454535e-01  2.4077947e+00  2.1995032e+00 -4.0448079e+00\n -9.2925215e-01  2.2726848e+00 -1.7401269e-01  5.2170229e-01\n  4.3472964e-01 -4.4175196e+00 -1.7052845e+00 -1.8668878e-01\n  1.6842152e+00  1.8334684e+00  1.9559307e-02  1.0533800e+00\n  1.6240237e+00 -5.1595324e-01 -1.0556552e+00 -1.8572745e+00\n -4.4830614e-01  1.2938776e+00 -2.6437109e+00 -3.9279304e+00\n  6.7561090e-01  3.3770020e+00 -1.2377387e+00  6.3179296e-01\n -3.0890808e+00 -9.2200398e-01 -7.5395477e-01  1.4635874e+00\n -2.6328647e+00  5.8671838e-01 -3.1122048e+00 -1.4853683e+00\n -3.5925019e+00 -9.0457928e-01  2.6442163e+00  7.3590726e-01\n  1.6794238e+00 -3.2729104e-01 -1.7280924e-01 -2.1610258e+00\n  2.0986254e+00 -1.4968735e+00 -1.1144214e+00 -2.0745757e+00\n  2.4610586e+00 -5.3111992e+00  6.6212231e-01 -2.6543918e+00\n  1.2785629e+00 -1.1522425e+00 -1.0213540e-01 -9.0020829e-01\n  2.2124939e+00  1.2656025e+00  1.7484128e+00  2.4436119e+00\n -5.1200920e-01  3.9480648e+00  3.5562128e-01 -1.0096823e+00\n -1.2655197e+00 -1.3710920e+00  4.8538360e-01  1.0193845e+00\n -6.8567353e-01  1.5078901e+00  1.1484847e+00  1.1693500e+00\n -1.9256405e+00 -8.6966836e-01  2.0926356e-01 -1.5142665e+00\n -1.6797714e+00 -2.8695924e+00 -4.1191903e-01  1.9779531e+00\n -1.5834309e+00 -3.6900871e+00  1.5921605e+00 -1.4703733e+00\n  2.0056138e+00 -1.2378743e+00 -2.1566374e+00  3.4771997e-01\n  2.8722532e+00 -3.0759056e+00 -3.9849904e-01  8.1287807e-01\n -1.0720620e+00 -1.5841624e+00  4.3312273e+00 -2.4475791e+00\n -1.7784846e+00 -1.2929100e+00  8.7318581e-01  1.7913809e+00\n  7.3232859e-01  6.6992486e-01 -3.7304037e+00  2.6036674e-01\n  7.4065693e-02  9.6584308e-01 -1.1477481e+00  3.0739110e+00\n -5.9495438e-02 -8.1894077e-02 -7.4207342e-01  1.5691304e+00\n  3.0630310e+00  7.4038243e-01 -9.9650455e-01 -5.5160624e-01\n -1.3176674e+00 -3.2868459e+00 -8.1009310e-01  3.2517961e-01\n -2.6843810e+00 -9.0371686e-01 -3.4887893e+00  3.0896013e+00\n -9.3788320e-01  1.1897588e-01  9.6492255e-01 -8.9322871e-01\n  1.9874659e+00  1.5735323e+00  1.2174255e+00 -1.6569481e+00\n -9.5430487e-01 -2.6639646e-01 -2.9983237e+00 -2.1904733e+00\n -3.8639185e-01  6.2347645e-01  3.7714205e+00 -1.0601476e+00\n -1.0001069e+00  8.8191777e-01 -1.4612850e+00 -1.5596120e+00\n  1.3283343e+00  2.1000891e+00 -1.1779108e+00 -7.5683695e-01\n -1.7087047e+00 -7.1810716e-01 -6.1134970e-01 -2.4914935e-01\n -2.0177565e+00  7.2806549e-01  5.8099061e-01  1.4585537e+00\n -2.2939477e+00 -1.5291135e+00 -1.5099289e+00 -3.2321315e+00\n  6.1497670e-01  2.3320947e+00 -3.6664815e+00  6.2144011e-01\n -1.7255962e+00 -1.7187570e+00  2.2244904e+00  3.1124595e-01\n -1.9233246e+00  2.9262867e+00 -6.4434284e-01  6.5985173e-01\n  3.7461834e-03 -2.1112857e+00 -2.0878343e-01  1.0766115e+00\n -2.4515038e+00 -1.2157291e+00  6.6348791e-01  6.9953376e-01\n -5.6131536e-01 -1.6413348e+00  1.0857105e+00  1.4758211e+00\n  2.8117948e+00 -5.8064111e-02  1.6607553e-01 -4.7130775e+00\n -3.7049344e-01  1.3344603e+00  3.2366285e-01  1.0987030e+00\n -1.6346524e+00  1.1686294e+00  2.3944382e-01 -7.4882221e-01\n -1.4736948e+00 -3.0995882e-01  2.0879261e+00  3.3721754e-01\n -1.7368939e+00 -6.8033016e-01 -2.5193825e+00  1.2684470e+00\n  1.2490822e+00  2.9506516e+00 -1.3877697e-01 -6.4308608e-01\n -5.3445492e+00 -6.6599011e-01  1.7340769e-01 -3.0730164e+00\n  1.4694253e+00  1.5803531e+00 -7.4518591e-02  1.3910463e+00\n  2.6198113e-01  5.9126120e+00  4.1149664e+00  3.7905061e+00\n  6.1283034e-01 -1.8621488e-01  4.1750160e-01  2.4414737e+00\n -4.9565382e+00  1.5875116e-01  1.8287042e+00 -1.5839664e+00\n -5.1569861e-01 -2.1890948e+00  6.2454796e-01  1.0140430e-01\n  2.9440637e+00 -3.1108832e-01 -1.0851415e+00  1.9169365e+00\n  1.4631879e-01 -5.2558589e-01  1.0758524e+00  1.8683195e+00\n  4.1380458e+00 -6.2021714e-01  9.9774951e-01  1.1183604e+00\n -1.9896706e+00  1.4364551e+00  1.7458793e+00 -9.9778289e-01\n  1.3292212e+00  2.3253212e-02 -1.7088943e+00  5.1940012e-01\n  1.2845680e+00 -2.0319632e-01 -3.2012630e+00  1.5914700e+00]"
     ]
    }
   ],
   "source": [
    "embedding_model = tf.keras.Model(text_input, doc.vector)\n",
    "sentences = tf.constant([\"Basha\"])\n",
    "print(embedding_model(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_word_ids': <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
       " array([[  101,  7632,  1010,  1045,  1005,  1049,  7527,  1010,  1045,\n",
       "          1005,  1049,  2183,  2000,  2022,  3015,  2055,  2129,  2023,\n",
       "          2227,  2006,  7733,  2003,  1037,  3019,  2455, 14192,  2030,\n",
       "          2065,  2045,  2003,  2166,  2006,  7733,  2008,  2081,  2009,\n",
       "          1012,  1996,  2466,  2003,  2055,  2129,  9274,  2165,  1037,\n",
       "          3861,  1997,  7733,  1998,  1037,  2227,  2001,  2464,  2006,\n",
       "          1996,  4774,  1012,  9274,  2987,  1005,  1056,  2113,  2065,\n",
       "          1996,  2455, 14192,  2001,  2580,  2011,  2166,  2006,  7733,\n",
       "          1010,  2030,  2065,  2009,  2003,  2074,  1037,  3019,  2455,\n",
       "         14192,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]])>,\n",
       " 'input_type_ids': <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
       " array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>,\n",
       " 'input_mask': <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
       " array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ccc9907020a360c0774b7240d7189d7caac06a5804f44f1a6c385a36278d3a41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
